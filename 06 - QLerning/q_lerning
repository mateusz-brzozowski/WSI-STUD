import gym
import random
import numpy as np

ALL_EPISODES = [1000]
LEARNING_RATE = 0.8
MAX_STEPS = 200
GAMMA = 0.9

MAX_EPSILON = 1.0
MIN_EPSILON = 0.001
DECAY_RATE = 0.00005


def default_reward(env, state):
    row, col = divmod(state, 8)
    if env.desc[row, col] == b'G':
        return 1
    return 0

def first_reward(env, state):
    row, col = divmod(state, 8)
    if env.desc[row, col] == b'G':
        return 1
    elif env.desc[row, col] == b'H':
        return -1
    return 0

def second_reward(env, state):
    row, col = divmod(state, 8)
    if env.desc[row, col] == b'G':
        return 10
    elif env.desc[row, col] == b'H':
        return -5
    else:
        return -1

REWARD_FUNCTIONS = [default_reward, first_reward, second_reward]

def q_lerning(env, episodes, reward_function):
    qtable = np.zeros((env.observation_space.n, env.action_space.n))
    epsilon = MAX_EPSILON
    for episode in range(episodes):
        state = env.reset()
        done = False
        for _ in range(MAX_STEPS):
            exp_exp_tradeoff = random.uniform(0, 1)
            if exp_exp_tradeoff > epsilon:
                action = np.argmax(qtable[state,:])
            else:
                action = env.action_space.sample()
            new_state, _, done, _ = env.step(action)
            reward = reward_function(env, new_state)
            qtable[state, action] = qtable[state, action] + LEARNING_RATE * (reward + GAMMA * np.max(qtable[new_state, :]) - qtable[state, action])
            state = new_state
            if done == True:
                break
        epsilon = MIN_EPSILON + (MAX_EPSILON - MIN_EPSILON) * np.exp(-DECAY_RATE*episode)
    return qtable


def test_q_lerning(env, qtable):
    env.reset()
    total_succes = 0
    for _ in range(1000):
        state = env.reset()
        done = False
        for _ in range(MAX_STEPS):
            action = np.argmax(qtable[state,:])
            new_state, reward, done, _ = env.step(action)
            if done == True:
                if reward == 1.0:
                    total_succes += 1
                break
            state = new_state
    env.close()
    return total_succes

def run_q_lerning(total_episodes, reward_function):
    env = gym.make("FrozenLake8x8-v1")
    qtable = q_lerning(env, total_episodes, reward_function)
    return test_q_lerning(env, qtable)


def main():
    for reward_function in REWARD_FUNCTIONS:
        print(reward_function.__name__)
        print('episodes | avg success')
        print('---------|------------')
        for total_episodes in ALL_EPISODES:
            total_succes = run_q_lerning(total_episodes, reward_function)
            print(f'{total_episodes:8} | {((total_succes/1000) * 100):.5f}' + "%")

if __name__ == "__main__":
    main()